#!/bin/bash
#SBATCH --partition=short        ### Partition (like a queue in PBS)
#SBATCH --job-name=csv     ### Job Name
#SBATCH --output=./logs/06_csv_%j.out         ### File in which to store job output
#SBATCH --error=./logs/06_csv_%j.err          ### File in which to store job error messages
#SBATCH --time=0-06:00:00       ### Wall clock time limit in Days-HH:MM:SS
#SBATCH --nodes=1               ### Number of nodes needed for the job
#SBATCH --ntasks-per-node=1     ### Number of tasks to be launched per Node
#SBATCH --mem=20G
#SBATCH --account=kuhl_lab      ### Account used for job submission
#SBATCH --partition=kuhl
#SBATCH --mail-user=wanjiag@uoregon.edu
#SBATCH --mail-type=END 
                 
module load tensorflow

conda activate /gpfs/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/monstera_conda_env 

python /gpfs/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/python_code/extract_values.py
