{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from glob import glob \n",
    "from os.path import join as opj\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import ttest_rel\n",
    "import seaborn as sns\n",
    "\n",
    "def cleaning(df):\n",
    "    '''\n",
    "    clearning up files for conditions\n",
    "    '''\n",
    "    \n",
    "    df['n_pic'] = df['npic'].str.split('_', expand=True)[[0]]\n",
    "    df['n_int'] = pd.to_numeric(df['npic'], errors='coerce')\n",
    "    df['TR'] = df['onset'].apply(np.floor).astype('int')\n",
    "    \n",
    "    tmp = df['condition'].str.split('/', expand=True)\n",
    "    \n",
    "    df['pair'] = tmp[[0]].squeeze().str.extract('(\\w+)')\n",
    "    \n",
    "    tmp1 = tmp[[1]].squeeze().str.split(',', expand=True)\n",
    "    df['destination'] = tmp1[[0]].squeeze().str.extract('(\\w+)')\n",
    "    df['valid'] = pd.to_numeric(tmp1[[1]].squeeze(), errors='coerce').apply(lambda x: {0: True, 1: False}.get(x, None))\n",
    "    df['catch'] = tmp1[[3]].squeeze().notnull()\n",
    "    \n",
    "    def segment(x):\n",
    "        if x <= 25:\n",
    "            return 'same'\n",
    "        elif x <= 50:\n",
    "            return 'early-similar'\n",
    "        elif x <= 75:\n",
    "            return 'late-similar'\n",
    "        elif x <= 100:\n",
    "            return 'different'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    \n",
    "    df['segment'] = df['n_int'].apply(segment)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def cleaning2(df):\n",
    "    '''\n",
    "    remove duplicated lines for multiple pictures\n",
    "    only save one line per second\n",
    "    '''\n",
    "    \n",
    "    df = df.loc[df['catch'] == False]\n",
    "    df = df.loc[df['segment'].notnull()]\n",
    "    df = df.drop(columns=['onset', 'design_onset', 'design_end', 'n_pic', 'npic', 'condition', 'n_int', 'catch'])\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    df['within_trial_TR'] = df.groupby(['sub','round','trial'])['TR'].rank(method = 'dense').astype('int')\n",
    "    #df['odd_even'] = df['round'].apply(lambda x: 'even' if x%2 == 0 else 'odd')\n",
    "    \n",
    "    df['round'] = df['round'].astype('int')\n",
    "    df['trial'] = df['trial'].astype('int')\n",
    "\n",
    "    return df\n",
    "\n",
    "def cleaning3(fmri_df):\n",
    "    '''\n",
    "    quick cleaning fMRI dataframe\n",
    "    '''\n",
    "    fmri_df.rename(columns={'Unnamed: 0':'TR'}, inplace=True)\n",
    "    fmri_df['round'] = fmri_df['run'].squeeze().str.extract('(\\d+)').astype('int')\n",
    "    fmri_df['sub'] = fmri_df['sub'].squeeze().str.extract('(\\d+)').astype('int')\n",
    "    fmri_df = fmri_df.drop(columns=['run', 'roi'])\n",
    "    return fmri_df\n",
    "\n",
    "def pairwise_correlation(curr_tr_df):\n",
    "    properties = curr_tr_df.iloc[:, :9]\n",
    "    # calculate correlation for every trial combination\n",
    "    corr_df = curr_tr_df.T.iloc[9:].astype(float).corr() \n",
    "    # taking only the upper triangle of the correlation matrix\n",
    "    corr_df = corr_df.where(np.triu(np.ones(corr_df.shape)).astype(np.bool))\n",
    "    # reorganize into long format\n",
    "    corr_df = corr_df.stack().reset_index()\n",
    "    # rename columns\n",
    "    corr_df.columns = ['x', 'y', 'cor']\n",
    "    overall_df = corr_df.merge(properties, right_index=True, left_on = 'x', how='left').merge(properties, right_index=True, left_on = 'y', how='left')\n",
    "\n",
    "    return overall_df\n",
    "\n",
    "def per_tr_calculation(df):\n",
    "    outputs = []\n",
    "    trs = df['within_trial_TR'].unique()\n",
    "    for curr_tr in trs:\n",
    "\n",
    "        curr_tr_df = df.loc[df['within_trial_TR'] == curr_tr]\n",
    "        curr_tr_output = pairwise_correlation(curr_tr_df)\n",
    "        outputs.append(curr_tr_output)\n",
    "\n",
    "    output_df = pd.concat(outputs)\n",
    "    output_df['roi'] = roi\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "def save_file(subnum, output_df, file_name):\n",
    "    sub_out_dir = opj(output_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    if not os.path.isdir(sub_out_dir):\n",
    "        os.makedirs(sub_out_dir)\n",
    "    \n",
    "    out_file = opj(sub_out_dir, file_name)\n",
    "    output_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "rois_dict = {\n",
    "    'ca1-body_thre_0.5_masked':'ca1-body',\n",
    "    'ca23dg-body_thre_0.5_masked':'ca23dg-body',\n",
    "    \n",
    "    #'ca23dg_thre_0.5_masked':'ca23dg',\n",
    "    #'ca1_thre_0.5_masked':'ca1', \n",
    "    'evc_2_epi_thre_0.5_masked':'evc', \n",
    "    'ppa_mni_2_epi_thre_0.5_masked':'ppa'\n",
    "}\n",
    "\n",
    "behav_dir = \"/home/wanjiag/projects/MONSTERA/derivatives/csv_files/behavior/\"\n",
    "preprocess_dir = '/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/preprocess'\n",
    "output_dir = \"/home/wanjiag/projects/MONSTERA/derivatives/csv_files/python/\"\n",
    "fMRI_dir = \"/home/wanjiag/projects/MONSTERA/derivatives/csv_files/fMRI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-MONSTERA01', 'sub-MONSTERA02', 'sub-MONSTERA03', 'sub-MONSTERA04', 'sub-MONSTERA05', 'sub-MONSTERA06', 'sub-MONSTERA07', 'sub-MONSTERA08', 'sub-MONSTERA09', 'sub-MONSTERA10', 'sub-MONSTERA11', 'sub-MONSTERA12', 'sub-MONSTERA13', 'sub-MONSTERA14', 'sub-MONSTERA15', 'sub-MONSTERA16', 'sub-MONSTERA17', 'sub-MONSTERA18', 'sub-MONSTERA19', 'sub-MONSTERA20', 'sub-MONSTERA21', 'sub-MONSTERA22', 'sub-MONSTERA23', 'sub-MONSTERA24', 'sub-MONSTERA25', 'sub-MONSTERA26', 'sub-MONSTERA27', 'sub-MONSTERA28', 'sub-MONSTERA29', 'sub-MONSTERA31', 'sub-MONSTERA32', 'sub-MONSTERA33', 'sub-MONSTERA35', 'sub-MONSTERA36', 'sub-MONSTERA37', 'sub-MONSTERA38', 'sub-MONSTERA39', 'sub-MONSTERA40', 'sub-MONSTERA41', 'sub-MONSTERA42', 'sub-MONSTERA43', 'sub-MONSTERA44', 'sub-MONSTERA45', 'sub-MONSTERA46', 'sub-MONSTERA47', 'sub-MONSTERA48', 'sub-MONSTERA49', 'sub-MONSTERA50', 'sub-MONSTERA51', 'sub-MONSTERA52', 'sub-MONSTERA53']\n",
      "['sub-MONSTERA06', 'sub-MONSTERA07', 'sub-MONSTERA08', 'sub-MONSTERA09', 'sub-MONSTERA10', 'sub-MONSTERA11', 'sub-MONSTERA12', 'sub-MONSTERA15', 'sub-MONSTERA16', 'sub-MONSTERA17', 'sub-MONSTERA18', 'sub-MONSTERA19', 'sub-MONSTERA21', 'sub-MONSTERA22', 'sub-MONSTERA25', 'sub-MONSTERA26', 'sub-MONSTERA28', 'sub-MONSTERA29', 'sub-MONSTERA31', 'sub-MONSTERA32', 'sub-MONSTERA33', 'sub-MONSTERA35', 'sub-MONSTERA36', 'sub-MONSTERA37', 'sub-MONSTERA38', 'sub-MONSTERA39', 'sub-MONSTERA40', 'sub-MONSTERA41', 'sub-MONSTERA42', 'sub-MONSTERA43', 'sub-MONSTERA44', 'sub-MONSTERA45', 'sub-MONSTERA46', 'sub-MONSTERA47', 'sub-MONSTERA48', 'sub-MONSTERA49', 'sub-MONSTERA50', 'sub-MONSTERA51', 'sub-MONSTERA52', 'sub-MONSTERA53']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_list = [x for x in glob(os.path.join(preprocess_dir, '*sub-MONSTERA*/'))]\n",
    "subs = list(map(lambda f: f[len(os.path.commonpath(f_list))+1:-1], f_list))\n",
    "subs.sort()\n",
    "print(subs)\n",
    "\n",
    "bad = ['sub-MONSTERA01', 'sub-MONSTERA02', 'sub-MONSTERA03', 'sub-MONSTERA04', 'sub-MONSTERA05',\n",
    "        'sub-MONSTERA13', 'sub-MONSTERA14', 'sub-MONSTERA20', 'sub-MONSTERA23', 'sub-MONSTERA24', 'sub-MONSTERA27', \n",
    "        'sub-MONSTERA30', 'sub-MONSTERA34']\n",
    "\n",
    "todo_subs = list(set(subs) - set(bad))\n",
    "todo_subs.sort()\n",
    "print(todo_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(todo_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "postscan_summary = pd.read_csv('/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/R-analysis/csv_files/postscan_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "postscan_summary = postscan_summary.drop(columns = ['m','max','min','median','range','n'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>sub</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>pair4_south</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>pair4_south</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>pair4_south</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>pair4_south</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>pair4_south</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          route  sub  mode\n",
       "0    pair1_east    6     6\n",
       "1    pair1_east    8     7\n",
       "2    pair1_east   10     8\n",
       "3    pair1_east   12     8\n",
       "4    pair1_east   16     9\n",
       "..          ...  ...   ...\n",
       "75  pair4_south   45     9\n",
       "76  pair4_south   47     9\n",
       "77  pair4_south   49     9\n",
       "78  pair4_south   51     9\n",
       "79  pair4_south   53     9\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postscan_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>sub</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pair1_east</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pair4_south</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>pair4_south</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          route  sub  mode\n",
       "0    pair1_east    6     6\n",
       "11   pair1_east   38     6\n",
       "16   pair1_east   48     6\n",
       "61  pair4_south   11     6\n",
       "63  pair4_south   17     6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postscan_summary.loc[postscan_summary['mode'] <=6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between MoI and destination (not including MoI or destination)\n",
    "Average first then correlate within each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            same\n",
       "1            same\n",
       "2            same\n",
       "3            same\n",
       "4            same\n",
       "          ...    \n",
       "2875    different\n",
       "2876    different\n",
       "2877    different\n",
       "2878    different\n",
       "2879    different\n",
       "Name: segment, Length: 2880, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for sub in todo_subs:\n",
    "    \n",
    "    subnum = re.findall('\\d+', sub)[0]\n",
    "    print('---{}---'.format(subnum))\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    \n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    behav_df = behav_df.merge(postscan_summary.rename(columns={\"route\": \"pair\"}), on=['sub', 'pair'], how='left')\n",
    "    behav_df['ceiling'] = behav_df['mode'] + 1\n",
    "    behav_df['floor'] = behav_df['mode'] - 1\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    \n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "                \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "              \n",
    "        df = behav_df.merge(rolling_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        same_df = df.loc[(df['segment']=='same')].reset_index(drop = True)\n",
    "        same_avg_df = same_df.groupby(['sub','round','trial','pair','destination','valid']).mean().drop(columns=['within_trial_TR','TR','mode','ceiling','floor']).reset_index()\n",
    "        \n",
    "        moi_df = df.loc[(df['within_trial_TR']<=df['ceiling']+6) & (df['within_trial_TR']>df['ceiling'])].reset_index(drop = True)\n",
    "        moi_avg_df = moi_df.groupby(['sub','round','trial','pair','destination','valid']).mean().drop(columns=['within_trial_TR','TR','mode','ceiling','floor']).reset_index()\n",
    "        \n",
    "        numeric_moi_df = moi_avg_df[moi_avg_df.columns[pd.to_numeric(moi_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "        numeric_same_df = same_avg_df[same_avg_df.columns[pd.to_numeric(same_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "\n",
    "        result_df = moi_avg_df[['sub','round','trial','pair','destination','valid']].copy().reset_index(drop = True)\n",
    "        result_df['cor'] = numeric_moi_df.corrwith(numeric_same_df, axis = 1) \n",
    "\n",
    "        result_df['roi'] = roi\n",
    "\n",
    "        results =  pd.concat([results, result_df]).reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/R-analysis/csv_files/3s_post_MoI_within_trials_avg_then_correlations.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each timepoint correlate to MoI or Destination separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for sub in todo_subs:\n",
    "    subnum = re.findall('\\d+', sub)[0]\n",
    "    print('---{}---'.format(subnum))\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    \n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    behav_df = behav_df.merge(postscan_summary.rename(columns={\"route\": \"pair\"}), on=['sub', 'pair'], how='left')\n",
    "    behav_df['ceiling'] = behav_df['mode'] + 1\n",
    "    behav_df['floor'] = behav_df['mode'] - 1\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    \n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "        \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "\n",
    "        df = behav_df.merge(rolling_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        same_df = df.loc[(df['segment']=='same')].reset_index(drop = True)\n",
    "        \n",
    "        moi_df = df.loc[(df['within_trial_TR']<=df['ceiling']) & (df['within_trial_TR']>=df['floor'])].reset_index(drop = True)\n",
    "        moi_avg_df = moi_df.groupby(['sub','round','trial','pair','destination','valid']).mean().drop(columns=['within_trial_TR','TR','mode','ceiling','floor']).reset_index()\n",
    "\n",
    "        for row in range(moi_avg_df.shape[0]):\n",
    "            curr_trial_moi = moi_avg_df.iloc[row]\n",
    "            curr_trial = same_df.loc[(same_df['sub']==curr_trial_moi['sub']) & (same_df['trial']==curr_trial_moi['trial']) & (same_df['round']==curr_trial_moi['round'])]\n",
    "\n",
    "            numeric_df = curr_trial[curr_trial.columns[pd.to_numeric(curr_trial.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "            curr_trial_moi = moi_avg_df.iloc[[row],:]\n",
    "            numeric_moi_df = curr_trial_moi[curr_trial_moi.columns[pd.to_numeric(curr_trial_moi.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "\n",
    "            result_df = curr_trial[['sub','round','trial','pair','destination','valid','within_trial_TR']].copy().reset_index(drop = True)\n",
    "            result_df['cor'] = numeric_df.corrwith(numeric_moi_df.iloc[0], axis = 1) \n",
    "\n",
    "            result_df['roi'] = roi\n",
    "\n",
    "            results =  pd.concat([results, result_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/R-analysis/csv_files/MoI_within_trials_correlations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for sub in todo_subs:\n",
    "    subnum = re.findall('\\d+', sub)[0]\n",
    "    print('---{}---'.format(subnum))\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    \n",
    "    dest_behav_df = behav_df_tmp[behav_df_tmp[\"npic\"].str.contains(\"destination\")]\n",
    "    dest_behav_df = dest_behav_df.drop(columns=['onset', 'design_onset', 'design_end', 'n_pic', 'npic', 'condition', 'n_int', 'catch', 'segment'])\n",
    "    extra = dest_behav_df.copy()\n",
    "    extra['TR'] = extra['TR']+1\n",
    "    dest_behav_df = pd.concat([dest_behav_df, extra])\n",
    "    \n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    \n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "        \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "        \n",
    "        # problem with rolling function, so calculating the last sec manually\n",
    "        last_two_sec = fmri_df.loc[(fmri_df['TR']==450) | (fmri_df['TR']==451)]\n",
    "        last_two_sec_avg = last_two_sec.groupby(['sub','round']).mean().reset_index()\n",
    "        last_two_sec_avg['TR'] = 451\n",
    "        \n",
    "        # Combine together to get fmri data\n",
    "        fmri_df = pd.concat([rolling_df.dropna(), last_two_sec_avg]).reset_index(drop = True)\n",
    "        \n",
    "        # template for each destination for each trial\n",
    "        dest_df = dest_behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left').groupby(['sub', 'round', 'trial', 'pair', 'destination', 'valid']).mean().reset_index().drop(columns = 'TR')\n",
    "        \n",
    "        df = behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        same_df = df.loc[(df['segment']=='same')].reset_index().drop(columns = 'TR')\n",
    "        \n",
    "        for row in range(dest_df.shape[0]):\n",
    "            curr_trial_dest = dest_df.iloc[row]\n",
    "            curr_trial = same_df.loc[(same_df['sub']==curr_trial_dest['sub']) & (same_df['trial']==curr_trial_dest['trial']) & (same_df['round']==curr_trial_dest['round'])]\n",
    "        \n",
    "            #numeric_same_df = curr_trial[curr_trial.columns[pd.to_numeric(curr_trial.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "            #numeric_dest_df = curr_trial_dest[curr_trial_dest.columns[pd.to_numeric(curr_trial_dest.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "        \n",
    "            numeric_df = curr_trial[curr_trial.columns[pd.to_numeric(curr_trial.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "            curr_trial_dest = dest_df.iloc[[row],:]\n",
    "            numeric_dest_df = curr_trial_dest[curr_trial_dest.columns[pd.to_numeric(curr_trial_dest.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "        \n",
    "            result_df = curr_trial[['sub','round','trial','pair','destination','valid','within_trial_TR']].copy().reset_index(drop = True)\n",
    "            result_df['cor'] = numeric_df.corrwith(numeric_dest_df.iloc[0], axis = 1) \n",
    "            \n",
    "            result_df['roi'] = roi\n",
    "            \n",
    "            results =  pd.concat([results, result_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/R-analysis/csv_files/destinations_within_trials_correlations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average within same segment then correlate to MoI or Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for sub in todo_subs:\n",
    "    \n",
    "    subnum = re.findall('\\d+', sub)[0]\n",
    "    print('---{}---'.format(subnum))\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    \n",
    "    dest_behav_df = behav_df_tmp[behav_df_tmp[\"npic\"].str.contains(\"destination\")]\n",
    "    dest_behav_df = dest_behav_df.drop(columns=['onset', 'design_onset', 'design_end', 'n_pic', 'npic', 'condition', 'n_int', 'catch', 'segment'])\n",
    "    extra = dest_behav_df.copy()\n",
    "    extra['TR'] = extra['TR']+1\n",
    "    dest_behav_df = pd.concat([dest_behav_df, extra])\n",
    "    \n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    \n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "                \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "        \n",
    "        # problem with rolling function, so calculating the last sec manually\n",
    "        last_two_sec = fmri_df.loc[(fmri_df['TR']==450) | (fmri_df['TR']==451)]\n",
    "        last_two_sec_avg = last_two_sec.groupby(['sub','round']).mean().reset_index()\n",
    "        last_two_sec_avg['TR'] = 451\n",
    "        \n",
    "        # Combine together to get fmri data\n",
    "        fmri_df = pd.concat([rolling_df.dropna(), last_two_sec_avg]).reset_index(drop = True)\n",
    "        \n",
    "        # same segment\n",
    "        df = behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        same_df = df.loc[(df['segment']=='same')].reset_index(drop = True).drop(columns = 'TR')\n",
    "        same_avg_df = same_df.groupby(['sub','round','trial','pair','destination','valid']).mean().reset_index().drop(columns = 'within_trial_TR')\n",
    "               \n",
    "        # each destination for each trial\n",
    "        dest_df = dest_behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        '''\n",
    "        last_sec_trial = df.loc[df['within_trial_TR'] ==24]\n",
    "        \n",
    "        if(subnum == '47'):\n",
    "            print('fixing problematic trial')\n",
    "            problem_trial = df.loc[(df['round']==1) & (df['trial']==1)].loc[df['within_trial_TR']==23]\n",
    "            print(problem_trial)\n",
    "            last_sec_trial = pd.concat([last_sec_trial, problem_trial])\n",
    "        if(last_sec_trial.shape[0] != 120):\n",
    "            print('===============subject with extra within_trial_TR===============')\n",
    "        dest_avg_df = pd.concat([dest_df, last_sec_trial]).groupby(['sub','round','trial','pair','destination','valid']).mean().reset_index().drop(columns = 'TR')\n",
    "        '''\n",
    "        dest_avg_df = dest_df.groupby(['sub','round','trial','pair','destination','valid']).mean().reset_index().drop(columns = 'TR')\n",
    "\n",
    "        \n",
    "        numeric_dest_df = dest_avg_df[dest_avg_df.columns[pd.to_numeric(dest_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "        numeric_same_df = same_avg_df[same_avg_df.columns[pd.to_numeric(same_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "\n",
    "        result_df = dest_avg_df[['sub','round','trial','pair','destination','valid']].copy().reset_index(drop = True)\n",
    "        result_df['cor'] = numeric_dest_df.corrwith(numeric_same_df, axis = 1) \n",
    "\n",
    "        result_df['roi'] = roi\n",
    "\n",
    "        results =  pd.concat([results, result_df]).reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/R-analysis/csv_files/destinations_within_trials_avg_then_correlations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for sub in todo_subs:\n",
    "    \n",
    "    subnum = re.findall('\\d+', sub)[0]\n",
    "    print('---{}---'.format(subnum))\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    \n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    behav_df = behav_df.merge(postscan_summary.rename(columns={\"route\": \"pair\"}), on=['sub', 'pair'], how='left')\n",
    "    behav_df['ceiling'] = behav_df['mode'] + 1\n",
    "    behav_df['floor'] = behav_df['mode'] - 1\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    \n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "                \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "              \n",
    "        df = behav_df.merge(rolling_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        same_df = df.loc[(df['segment']=='same')].reset_index(drop = True)\n",
    "        same_avg_df = same_df.groupby(['sub','round','trial','pair','destination','valid']).mean().drop(columns=['within_trial_TR','TR','mode','ceiling','floor']).reset_index()\n",
    "        \n",
    "        moi_df = df.loc[(df['within_trial_TR']<=df['ceiling']) & (df['within_trial_TR']>=df['floor'])].reset_index(drop = True)\n",
    "        moi_avg_df = moi_df.groupby(['sub','round','trial','pair','destination','valid']).mean().drop(columns=['within_trial_TR','TR','mode','ceiling','floor']).reset_index()\n",
    "        \n",
    "        numeric_moi_df = moi_avg_df[moi_avg_df.columns[pd.to_numeric(moi_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "        numeric_same_df = same_avg_df[same_avg_df.columns[pd.to_numeric(same_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "\n",
    "        result_df = moi_avg_df[['sub','round','trial','pair','destination','valid']].copy().reset_index(drop = True)\n",
    "        result_df['cor'] = numeric_moi_df.corrwith(numeric_same_df, axis = 1) \n",
    "\n",
    "        result_df['roi'] = roi\n",
    "\n",
    "        results =  pd.concat([results, result_df]).reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/R-analysis/csv_files/MoI_within_trials_avg_then_correlations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
