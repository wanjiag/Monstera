{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from glob import glob \n",
    "from os.path import join as opj\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import scipy.stats as stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    clearning up files for conditions\n",
    "    '''\n",
    "    \n",
    "    df['n_pic'] = df['npic'].str.split('_', expand=True)[[0]]\n",
    "    df['TR'] = df['onset'].apply(np.floor).astype('int')\n",
    "    \n",
    "    tmp = df['condition'].str.split('/', expand=True)\n",
    "    \n",
    "    df['pair'] = tmp[[0]].squeeze().str.extract('(\\w+)')\n",
    "    \n",
    "    tmp1 = tmp[[1]].squeeze().str.split(',', expand=True)\n",
    "    df['destination'] = tmp1[[0]].squeeze().str.extract('(\\w+)')\n",
    "    df['valid'] = pd.to_numeric(tmp1[[1]].squeeze(), errors='coerce').apply(lambda x: {0: True, 1: False}.get(x, None))\n",
    "    df['catch'] = tmp1[[3]].squeeze().notnull()\n",
    "    \n",
    "    def segment(x):\n",
    "        if x <= 25:\n",
    "            return 'same'\n",
    "        elif x <= 75:\n",
    "            return 'similar'\n",
    "        elif x <= 100:\n",
    "            return 'different'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    df['n_int'] = pd.to_numeric(df['npic'], errors='coerce')\n",
    "    df['segment'] = df['n_int'].apply(segment)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def cleaning2(df):\n",
    "    '''\n",
    "    remove duplicated lines for multiple pictures\n",
    "    only save one line per second\n",
    "    '''\n",
    "    \n",
    "    df = df.loc[df['catch'] == False]\n",
    "    df = df.loc[df['segment'].notnull()]\n",
    "    df = df.drop(columns=['onset', 'design_onset', 'design_end', 'n_pic', 'npic', 'condition', 'n_int', 'catch'])\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    df['within_trial_TR'] = df.groupby(['sub','round','trial'])['TR'].rank(method = 'dense').astype('int')\n",
    "    \n",
    "    df['round'] = df['round'].astype('int')\n",
    "    df['trial'] = df['trial'].astype('int')\n",
    "    \n",
    "    if subnum == 47:\n",
    "        df = df.loc[df['within_trial_TR']!=25]\n",
    "        \n",
    "        problem_trial = df.loc[(df['round']==1)&(df['trial']==1)]\n",
    "        added_sec = pd.DataFrame([[47,1,1,50,'pair2_north','pole','False','similar', 'na']], columns = problem_trial.columns)\n",
    "        problem_trial = pd.concat([problem_trial, added_sec])\n",
    "        problem_trial['within_trial_TR'] = problem_trial.groupby(['sub','round','trial'])['TR'].rank(method = 'dense').astype('int')\n",
    "        problem_trial = problem_trial.sort_values(by=['within_trial_TR'])\n",
    "        \n",
    "        print(df.shape)\n",
    "        df = df.loc[(df['round']!=1)|(df['trial']!=1)]\n",
    "        print(df.shape)\n",
    "        df = pd.concat([df, problem_trial])\n",
    "\n",
    "    return df\n",
    "\n",
    "def cleaning3(fmri_df):\n",
    "    '''\n",
    "    quick cleaning fMRI dataframe\n",
    "    '''\n",
    "    fmri_df.rename(columns={'Unnamed: 0':'TR'}, inplace=True)\n",
    "    fmri_df['round'] = fmri_df['run'].squeeze().str.extract('(\\d+)').astype('int')\n",
    "    fmri_df['sub'] = fmri_df['sub'].squeeze().str.extract('(\\d+)').astype('int')\n",
    "    fmri_df = fmri_df.drop(columns=['run', 'roi'])\n",
    "    return fmri_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_dict = {\n",
    "    'ca1-body_thre_0.5_masked':'ca1-body',\n",
    "    'ca23dg-body_thre_0.5_masked':'ca23dg-body',\n",
    "    'ppa_mni_2_epi_thre_0.5_masked':'ppa',\n",
    "    'evc_2_epi_thre_0.5_masked':'evc'\n",
    "}\n",
    "\n",
    "'''\n",
    "'lpc_2_epi_thre_0.5_masked':'lpc'\n",
    "'pfc_2_epi_thre_0.5_masked':'pfc',\n",
    "'ca23dg_thre_0.5_masked':'ca23dg',\n",
    "\n",
    "'ofc_orbital_2_epi_thre_0.5_masked':'ofc',\n",
    "'rsc_cingul-Post-dorsal_2_epi_thre_0.5_masked': 'rsc',\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "behav_dir = \"/home/wanjiag/projects/MONSTERA/derivatives/csv_files/behavior/\"\n",
    "fMRI_dir = \"/home/wanjiag/projects/MONSTERA/derivatives/csv_files/fMRI/\"\n",
    "all_subs = os.listdir(fMRI_dir)\n",
    "\n",
    "bads = ['01', '02', '03', '04', '05', '13', '14', '20', '23', '24', '27', '30', '34']\n",
    "for bad in bads:\n",
    "    all_subs = [x for x in all_subs if bad not in x ]\n",
    "\n",
    "all_subs.sort()\n",
    "subnums = [x[-2:] for x in all_subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subnums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "postscan_summary = pd.read_csv('/projects/kuhl_lab/wanjiag/MONSTERA/derivatives/scripts/R-analysis/csv_files/postscan_summary.csv')\n",
    "postscan_summary = postscan_summary.drop(columns = ['m','max','min','median','range','n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca23dg-body_thre_0.5_masked\n",
      "107\n",
      "ppa_mni_2_epi_thre_0.5_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n",
      "evc_2_epi_thre_0.5_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112\n",
      "ca1-body_thre_0.5_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "ca23dg-body_thre_0.5_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "ppa_mni_2_epi_thre_0.5_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanjiag/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1127: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evc_2_epi_thre_0.5_masked\n",
      "726\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "info = []\n",
    "for subnum in subnums:\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    \n",
    "    dest_behav_df = behav_df_tmp[behav_df_tmp[\"npic\"].str.contains(\"destination\")]\n",
    "    dest_behav_df = dest_behav_df.drop(columns=['onset', 'design_onset', 'design_end', 'n_pic', 'npic', 'condition', 'n_int', 'catch', 'segment'])\n",
    "    extra = dest_behav_df.copy()\n",
    "    extra['TR'] = extra['TR']+1\n",
    "    dest_behav_df = pd.concat([dest_behav_df, extra])\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    \n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "                \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "              \n",
    "        # problem with rolling function, so calculating the last sec manually\n",
    "        last_two_sec = fmri_df.loc[(fmri_df['TR']==450) | (fmri_df['TR']==451)]\n",
    "        last_two_sec_avg = last_two_sec.groupby(['sub','round']).mean().reset_index()\n",
    "        last_two_sec_avg['TR'] = 451\n",
    "        \n",
    "        # Combine together to get fmri data\n",
    "        fmri_df = pd.concat([rolling_df.dropna(), last_two_sec_avg]).reset_index(drop = True)\n",
    "        \n",
    "        # avg for each destination for each trial\n",
    "        dest_df = dest_behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left').groupby(['sub', 'round', 'trial', 'pair', 'destination', 'valid']).mean().reset_index().drop(columns = 'TR') \n",
    "            \n",
    "        # no round 2 for sub29\n",
    "        if subnum == '29':\n",
    "            dest_df = dest_df.loc[dest_df['round'] != 2]\n",
    "            \n",
    "        print(len(pd.to_numeric(dest_df.columns, errors='coerce').to_series().notnull()))\n",
    "        \n",
    "        for pair in dest_df.pair.unique():\n",
    "            \n",
    "            curr_df = dest_df.loc[dest_df.pair == pair].reset_index(drop = True)\n",
    "        \n",
    "            X = curr_df[curr_df.columns[pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()]]\n",
    "            #numeric_same_df = same_avg_df[same_avg_df.columns[pd.to_numeric(same_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "            y = curr_df.destination\n",
    "            groups = curr_df['round']\n",
    "\n",
    "            scalar = StandardScaler()\n",
    "            lr = LogisticRegression(penalty = 'l2', dual = True, solver = 'liblinear', max_iter=1000, C=0.001, random_state = 315)\n",
    "            #svc = LinearSVC(penalty = 'l2', C=0.001, random_state = 315)\n",
    "            pipeline = Pipeline([('transformer', scalar), ('estimator', lr)])\n",
    "\n",
    "            logo = LeaveOneGroupOut()\n",
    "            results = cross_val_score(pipeline, X, y, cv = logo, groups = groups, scoring = 'accuracy')\n",
    "            \n",
    "            info.append([subnum, roi])\n",
    "            predictions.append(results)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(predictions)\n",
    "df_pred['mean'] = df_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(info, columns = ['sub','roi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['sub'] = df_info['sub']\n",
    "df_pred['roi'] = df_info['roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sub = df_pred.groupby(['sub','roi'])['mean'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roi</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-body</th>\n",
       "      <td>0.521667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca23dg-body</th>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evc</th>\n",
       "      <td>0.727639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppa</th>\n",
       "      <td>0.513611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean\n",
       "roi                  \n",
       "ca1-body     0.521667\n",
       "ca23dg-body  0.486667\n",
       "evc          0.727639\n",
       "ppa          0.513611"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_sub.groupby(['roi']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.531474213138302 0.015500763884311436\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred_sub.loc[df_pred_sub['roi']=='ca1-body']['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6126615453042397 0.11488208966508487\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred_sub.loc[df_pred_sub['roi']=='ca23dg-body']['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.349742890964635 0.18488131077136627\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred_sub.loc[df_pred_sub['roi']=='ppa']['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.38464487612447 3.503428358293055e-17\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred_sub.loc[df_pred_sub['roi']=='evc']['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "info = []\n",
    "for subnum in subnums:\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    \n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    behav_df = behav_df.merge(postscan_summary.rename(columns={\"route\": \"pair\"}), on=['sub', 'pair'], how='left')\n",
    "    behav_df['ceiling'] = behav_df['mode'] + 1\n",
    "    behav_df['floor'] = behav_df['mode'] - 1\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    \n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "                \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "              \n",
    "        df = behav_df.merge(rolling_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        #same_df = df.loc[(df['segment']=='same')].reset_index(drop = True)\n",
    "        #same_avg_df = same_df.groupby(['sub','round','trial','pair','destination','valid']).mean().drop(columns=['within_trial_TR','TR','mode','ceiling','floor']).reset_index()\n",
    "        \n",
    "        moi_df = df.loc[(df['within_trial_TR']<=df['ceiling']) & (df['within_trial_TR']>=df['floor'])].reset_index(drop = True)\n",
    "        moi_avg_df = moi_df.groupby(['sub','round','trial','pair','destination','valid']).mean().drop(columns=['within_trial_TR','TR','mode','ceiling','floor']).reset_index()\n",
    "        \n",
    "        # no round 2 for sub29\n",
    "        if subnum == '29':\n",
    "            moi_avg_df = moi_avg_df.loc[moi_avg_df['round'] != 2]\n",
    "        \n",
    "        print(len(pd.to_numeric(moi_avg_df.columns, errors='coerce').to_series().notnull()))\n",
    "        \n",
    "        for pair in moi_avg_df.pair.unique():\n",
    "            \n",
    "            curr_df = moi_avg_df.loc[moi_avg_df.pair == pair].reset_index(drop = True)\n",
    "        \n",
    "            X = curr_df[curr_df.columns[pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()]]\n",
    "            #numeric_same_df = same_avg_df[same_avg_df.columns[pd.to_numeric(same_avg_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "            y = curr_df.destination\n",
    "            groups = curr_df['round']\n",
    "\n",
    "            scalar = StandardScaler()\n",
    "            lr = LogisticRegression(penalty = 'l2', dual = True, solver = 'liblinear', max_iter=1000, C=0.001, random_state = 315)\n",
    "            #svc = LinearSVC(penalty = 'l2', C=0.001, random_state = 315)\n",
    "            pipeline = Pipeline([('transformer', scalar), ('estimator', lr)])\n",
    "\n",
    "            logo = LeaveOneGroupOut()\n",
    "            results = cross_val_score(pipeline, X, y, cv = logo, groups = groups, scoring = 'accuracy')\n",
    "            print(results.mean())\n",
    "            predictions.append(results)\n",
    "            info.append([subnum, roi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(predictions)\n",
    "df_pred['mean'] = df_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(info, columns = ['sub','roi'])\n",
    "df_pred['sub'] = df_info['sub']\n",
    "df_pred['roi'] = df_info['roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sub = df_pred.groupby(['sub','roi'])['mean'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roi</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-body</th>\n",
       "      <td>0.509074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca23dg-body</th>\n",
       "      <td>0.512847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean\n",
       "roi                  \n",
       "ca1-body     0.509074\n",
       "ca23dg-body  0.512847"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_sub.groupby(['roi']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0532249619075826 0.2987197745476368\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred_sub.loc[df_pred_sub['roi']=='ca1-body']['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4358618384797643 0.15901456386478183\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred_sub.loc[df_pred_sub['roi']=='ca23dg-body']['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average all same segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "info = []\n",
    "\n",
    "for roi_file_name, roi in rois_dict.items():\n",
    "    print(roi_file_name)\n",
    "    for subnum in subnums:\n",
    "        print('---{}---'.format(subnum))\n",
    "\n",
    "        behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "        behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "\n",
    "        org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "        behav_df_tmp = cleaning(org_behav_df)\n",
    "        behav_df = cleaning2(behav_df_tmp)\n",
    "        \n",
    "        behav_df = behav_df.merge(postscan_summary.rename(columns={\"route\": \"pair\"}), on=['sub', 'pair'], how='left')\n",
    "        behav_df['ceiling'] = behav_df['mode'] + 1\n",
    "        behav_df['floor'] = behav_df['mode'] - 1\n",
    "\n",
    "        fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "        \n",
    "        #calculating rolling data\n",
    "        rolling_df = fmri_df.groupby(['sub','round']).rolling(window = 3, min_periods = 2, center = True, method = 'table').mean()\n",
    "        rolling_df = rolling_df.drop(columns= ['sub','round']).reset_index().drop(columns= 'level_2')\n",
    "        \n",
    "        # calculating no rolling data\n",
    "        df = behav_df.merge(rolling_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        \n",
    "        same_df = df.loc[df.segment == 'same'].drop(columns = ['TR','within_trial_TR'])\n",
    "        same_df = same_df.groupby(['sub','round','trial','pair','destination','valid']).mean().reset_index()\n",
    "        \n",
    "        # no round 2 for sub29\n",
    "        if subnum == '29':\n",
    "            same_df = same_df.loc[same_df['round'] != 2]\n",
    "        \n",
    "        for pair in same_df.pair.unique():\n",
    "            curr_df = same_df.loc[same_df.pair == pair]\n",
    "            curr_destination = curr_df.destination.unique()[0]\n",
    "            curr_df['cue_destination'] = np.where(curr_df.valid, curr_df.destination == curr_destination, curr_df.destination != curr_destination).astype(int)\n",
    "            \n",
    "            print(len(pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()))\n",
    "            X = curr_df[curr_df.columns[pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "            y = curr_df.cue_destination.reset_index(drop = True)\n",
    "            groups = curr_df['round'].reset_index(drop = True)\n",
    "\n",
    "            scalar = StandardScaler()\n",
    "            #lr = LogisticRegression(penalty = 'l2', dual = True, solver = 'liblinear', max_iter=1000, C=0.001, random_state = 315)\n",
    "            svc = LinearSVC(penalty = 'l2', C=0.001, random_state = 315)\n",
    "            pipeline = Pipeline([('transformer', scalar), ('estimator', svc)])\n",
    "            \n",
    "            logo = LeaveOneGroupOut()\n",
    "            results = cross_val_score(pipeline, X, y, cv = logo, groups = groups, scoring = 'accuracy')\n",
    "            print(results)\n",
    "            predictions.append(results)\n",
    "            info.append([subnum, roi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['mean'] = df_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(info, columns = ['sub','roi'])\n",
    "df_pred['sub'] = df_info['sub']\n",
    "df_pred['roi'] = df_info['roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roi</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-body</th>\n",
       "      <td>0.496944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca23dg-body</th>\n",
       "      <td>0.508657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evc</th>\n",
       "      <td>0.515833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppa</th>\n",
       "      <td>0.500648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean\n",
       "roi                  \n",
       "ca1-body     0.496944\n",
       "ca23dg-body  0.508657\n",
       "evc          0.515833\n",
       "ppa          0.500648"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_sub = df_pred.groupby(['sub','roi'])['mean'].mean().reset_index()\n",
    "df_pred_sub.groupby(['roi']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.37479529448772514 0.709843151050119\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred_sub.loc[df_pred_sub['roi']=='ca1-body']['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second by second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpc_2_epi_thre_0.5_masked\n",
      "---06---\n",
      "---07---\n",
      "---08---\n",
      "---09---\n",
      "---10---\n",
      "---11---\n",
      "---12---\n",
      "---15---\n",
      "---16---\n",
      "---17---\n",
      "---18---\n",
      "---19---\n",
      "---21---\n",
      "---22---\n",
      "---25---\n",
      "---26---\n",
      "---28---\n",
      "---29---\n",
      "---31---\n",
      "---32---\n",
      "---33---\n",
      "---35---\n",
      "---36---\n",
      "---37---\n",
      "---38---\n",
      "---39---\n",
      "---40---\n",
      "---41---\n",
      "---42---\n",
      "---43---\n",
      "---44---\n",
      "---45---\n",
      "---46---\n",
      "---47---\n",
      "---48---\n",
      "---49---\n",
      "---50---\n",
      "---51---\n",
      "---52---\n",
      "---53---\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for roi_file_name, roi in rois_dict.items():\n",
    "    print(roi_file_name)\n",
    "    for subnum in subnums:\n",
    "        print('---{}---'.format(subnum))\n",
    "\n",
    "        behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "        behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "\n",
    "        org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "        behav_df_tmp = cleaning(org_behav_df)\n",
    "        behav_df = cleaning2(behav_df_tmp)\n",
    "\n",
    "        fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "        \n",
    "        # calculating no rolling data\n",
    "        df = behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        \n",
    "        for i in range(6,7):\n",
    "            sec_df = df.loc[df.within_trial_TR == i].drop(columns = ['segment','TR','within_trial_TR'])\n",
    "            # no round 2 for sub29\n",
    "            if subnum == '29':\n",
    "                sec_df = sec_df.loc[sec_df['round'] != 2]\n",
    "                \n",
    "            for pair in sec_df.pair.unique():\n",
    "                curr_df = sec_df.loc[sec_df.pair == pair]\n",
    "                curr_destination = curr_df.destination.unique()[0]\n",
    "                #curr_df['cue_destination'] = np.where(curr_df.destination == curr_destination, 1, 0)\n",
    "                curr_df['cue_destination'] = np.where(curr_df.valid, curr_df.destination == curr_destination, curr_df.destination != curr_destination).astype(int)\n",
    "                if i == 7:\n",
    "                    print(len(pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()))\n",
    "                X = curr_df[curr_df.columns[pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "                y = curr_df.cue_destination.reset_index(drop = True)\n",
    "                groups = curr_df['round'].reset_index(drop = True)\n",
    "\n",
    "                scalar = StandardScaler()\n",
    "                lr = LogisticRegression(penalty = 'l2', dual = True, solver = 'liblinear', max_iter=1000, C=0.001, random_state = 315)\n",
    "                svc = LinearSVC(penalty = 'l2', C=0.001, random_state = 315)\n",
    "                pipeline = Pipeline([('transformer', scalar), ('estimator', svc)])\n",
    "\n",
    "                logo = LeaveOneGroupOut()\n",
    "                results = cross_val_score(pipeline, X, y, cv = logo, groups = groups, scoring = 'accuracy')\n",
    "                \n",
    "                info = list(results)\n",
    "                \n",
    "                predictions.append([subnum, i, pair] + info)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns=['subnum', 'within_trial_TR', 'pair', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['mean'] = predictions_df[predictions_df.columns[pd.to_numeric(predictions_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subnum</th>\n",
       "      <th>within_trial_TR</th>\n",
       "      <th>pair</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06</td>\n",
       "      <td>6</td>\n",
       "      <td>pair3_west</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06</td>\n",
       "      <td>6</td>\n",
       "      <td>pair1_east</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07</td>\n",
       "      <td>6</td>\n",
       "      <td>pair4_south</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07</td>\n",
       "      <td>6</td>\n",
       "      <td>pair2_north</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>6</td>\n",
       "      <td>pair3_west</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>pair4_south</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>pair3_west</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>pair1_east</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>pair4_south</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>pair2_north</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subnum  within_trial_TR         pair      1      2      3      4      5  \\\n",
       "0      06                6   pair3_west  0.625  0.375  0.625  0.375  0.750   \n",
       "1      06                6   pair1_east  0.375  0.875  0.500  0.500  0.875   \n",
       "2      07                6  pair4_south  0.625  0.625  0.500  0.625  0.250   \n",
       "3      07                6  pair2_north  0.375  0.500  0.500  0.500  0.500   \n",
       "4      08                6   pair3_west  0.625  0.375  0.750  0.500  0.375   \n",
       "..    ...              ...          ...    ...    ...    ...    ...    ...   \n",
       "75     51                6  pair4_south  0.250  0.625  0.500  0.750  0.875   \n",
       "76     52                6   pair3_west  0.750  0.375  0.500  0.625  0.375   \n",
       "77     52                6   pair1_east  0.500  0.375  0.500  0.500  0.375   \n",
       "78     53                6  pair4_south  0.625  0.500  0.625  0.500  0.250   \n",
       "79     53                6  pair2_north  0.625  0.625  0.500  0.500  0.125   \n",
       "\n",
       "        6      7      8      9     10    mean  \n",
       "0   0.500  0.750  0.750  0.375  0.750  0.5875  \n",
       "1   0.500  0.625  0.375  0.625  0.375  0.5625  \n",
       "2   0.750  0.500  0.500  0.625  0.625  0.5625  \n",
       "3   0.500  0.375  0.375  0.625  0.500  0.4750  \n",
       "4   0.625  0.500  0.125  0.500  0.500  0.4875  \n",
       "..    ...    ...    ...    ...    ...     ...  \n",
       "75  0.500  0.625  0.500  0.375  0.625  0.5625  \n",
       "76  0.625  0.625  0.000  0.875  0.750  0.5500  \n",
       "77  0.500  0.500  0.375  0.625  0.500  0.4750  \n",
       "78  0.125  0.250  0.625  0.750  0.500  0.4750  \n",
       "79  0.625  0.500  0.375  0.375  0.750  0.5000  \n",
       "\n",
       "[80 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "within_trial_TR\n",
       "6    0.507535\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.groupby(['within_trial_TR'])['mean'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "within_trial_TR\n",
       "1    0.499774\n",
       "2    0.505434\n",
       "3    0.493889\n",
       "4    0.502274\n",
       "5    0.510451\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.groupby(['within_trial_TR'])['mean'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prediction_df = predictions_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_prediction_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d02a13b7c3c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_prediction_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_prediction_df' is not defined"
     ]
    }
   ],
   "source": [
    "all_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5032261666666668"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.499774+0.505434+0.493889+0.502274+0.510451+0.507535)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding between pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for subnum in subnums:\n",
    "    print('---{}---'.format(subnum))\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "        \n",
    "        # calculating no rolling data\n",
    "        df = behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        \n",
    "        same_df = df.loc[df.within_trial_TR == 3].drop(columns = ['TR','within_trial_TR', 'segment'])\n",
    "\n",
    "        # no round 2 for sub29\n",
    "        if subnum == '29':\n",
    "            same_df = same_df.loc[same_df['round'] != 2]\n",
    "\n",
    "        curr_pair = same_df.pair.unique()[0]\n",
    "        same_df['cue_pair'] = np.where(same_df.pair == curr_pair, 0, 1)\n",
    "\n",
    "        print(len(pd.to_numeric(same_df.columns, errors='coerce').to_series().notnull()))\n",
    "        X = same_df[same_df.columns[pd.to_numeric(same_df.columns, errors='coerce').to_series().notnull()]].reset_index(drop = True)\n",
    "        y = same_df.cue_pair.reset_index(drop = True)\n",
    "        groups = same_df['round'].reset_index(drop = True)\n",
    "        \n",
    "        scalar = StandardScaler()\n",
    "        lr = LogisticRegression(penalty = 'l2', max_iter=1000, C=200.0, random_state = 315)\n",
    "        svc = LinearSVC(penalty = 'l2', C=0.001, random_state = 315)\n",
    "        pipeline = Pipeline([('transformer', scalar), ('estimator', svc)])\n",
    "\n",
    "        logo = LeaveOneGroupOut()\n",
    "        results = cross_val_score(pipeline, X, y, cv = logo, groups = groups, scoring = 'accuracy')\n",
    "        print(results)\n",
    "        predictions.append(results)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(predictions)\n",
    "df_pred['mean'] = df_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5542013888888888"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.249505230776209 0.0001289575579796593\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(a=df_pred['mean'], popmean=0.5) \n",
    "print(t_statistic , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
