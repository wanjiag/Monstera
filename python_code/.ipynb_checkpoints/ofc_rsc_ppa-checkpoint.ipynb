{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from glob import glob \n",
    "from os.path import join as opj\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    clearning up files for conditions\n",
    "    '''\n",
    "    \n",
    "    df['n_pic'] = df['npic'].str.split('_', expand=True)[[0]]\n",
    "    df['TR'] = df['onset'].apply(np.floor).astype('int')\n",
    "    \n",
    "    tmp = df['condition'].str.split('/', expand=True)\n",
    "    \n",
    "    df['pair'] = tmp[[0]].squeeze().str.extract('(\\w+)')\n",
    "    \n",
    "    tmp1 = tmp[[1]].squeeze().str.split(',', expand=True)\n",
    "    df['destination'] = tmp1[[0]].squeeze().str.extract('(\\w+)')\n",
    "    df['valid'] = pd.to_numeric(tmp1[[1]].squeeze(), errors='coerce').apply(lambda x: {0: True, 1: False}.get(x, None))\n",
    "    df['catch'] = tmp1[[3]].squeeze().notnull()\n",
    "    \n",
    "    def segment(x):\n",
    "        if x <= 25:\n",
    "            return 'same'\n",
    "        elif x <= 75:\n",
    "            return 'similar'\n",
    "        elif x <= 100:\n",
    "            return 'different'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    df['n_int'] = pd.to_numeric(df['npic'], errors='coerce')\n",
    "    df['segment'] = df['n_int'].apply(segment)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def cleaning2(df):\n",
    "    '''\n",
    "    remove duplicated lines for multiple pictures\n",
    "    only save one line per second\n",
    "    '''\n",
    "    \n",
    "    #df = df.loc[df['catch'] == False]\n",
    "    df = df.loc[df['segment'].notnull()]\n",
    "    df = df.drop(columns=['onset', 'design_onset', 'design_end', 'n_pic', 'npic', 'condition', 'n_int', 'catch'])\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    df['within_trial_TR'] = df.groupby(['sub','round','trial'])['TR'].rank(method = 'dense').astype('int')\n",
    "    #df['odd_even'] = df['round'].apply(lambda x: 'even' if x%2 == 0 else 'odd')\n",
    "    \n",
    "    df['round'] = df['round'].astype('int')\n",
    "    df['trial'] = df['trial'].astype('int')\n",
    "\n",
    "    return df\n",
    "\n",
    "def cleaning3(fmri_df):\n",
    "    '''\n",
    "    quick cleaning fMRI dataframe\n",
    "    '''\n",
    "    fmri_df.rename(columns={'Unnamed: 0':'TR'}, inplace=True)\n",
    "    fmri_df['round'] = fmri_df['run'].squeeze().str.extract('(\\d+)').astype('int')\n",
    "    fmri_df['sub'] = fmri_df['sub'].squeeze().str.extract('(\\d+)').astype('int')\n",
    "    fmri_df = fmri_df.drop(columns=['run', 'roi'])\n",
    "    return fmri_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_dict = {\n",
    "    'ofc_orbital_2_epi_thre_0.5_masked':'ofc',\n",
    "    'rsc_cingul-Post-dorsal_2_epi_thre_0.5_masked': 'rsc', \n",
    "    'ppa_mni_2_epi_thre_0.5_masked':'ppa'\n",
    "    \n",
    "}\n",
    "\n",
    "behav_dir = \"/home/wanjiag/projects/MONSTERA/derivatives/csv_files/behavior/\"\n",
    "fMRI_dir = \"/home/wanjiag/projects/MONSTERA/derivatives/csv_files/fMRI/\"\n",
    "all_subs = os.listdir(fMRI_dir)\n",
    "\n",
    "bads = ['01', '02', '03', '04', '05', '13', '14', '20', '23', '24', '27', '30', '34']\n",
    "for bad in bads:\n",
    "    all_subs = [x for x in all_subs if bad not in x ]\n",
    "\n",
    "all_subs.sort()\n",
    "subnums = [x[-2:] for x in all_subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subnums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for subnum in subnums:\n",
    "    print('---{}---'.format(subnum))\n",
    "    \n",
    "    behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "    behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "    \n",
    "    org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "    behav_df_tmp = cleaning(org_behav_df)\n",
    "    behav_df = cleaning2(behav_df_tmp)\n",
    "    \n",
    "    fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "    for roi_file_name, roi in rois_dict.items():\n",
    "        print(roi_file_name)\n",
    "        fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "        fmri_files.sort()\n",
    "        \n",
    "        fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "        fmri_df = cleaning3(fmri_df)\n",
    "        \n",
    "        # calculating no rolling data\n",
    "        df = behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left')\n",
    "        \n",
    "        same_df = df.loc[df.segment == 'same'].drop(columns = ['TR','within_trial_TR'])\n",
    "        same_df = same_df.groupby(['sub','round','trial','pair','destination','valid']).mean().reset_index()\n",
    "        \n",
    "        for pair in same_df.pair.unique():\n",
    "            curr_df = same_df.loc[same_df.pair == pair]\n",
    "            curr_destination = curr_df.destination.unique()[0]\n",
    "            curr_df['cue_destination'] = np.where(curr_df.valid, curr_df.destination == curr_destination, curr_df.destination != curr_destination).astype(int)\n",
    "            \n",
    "            X = curr_df[curr_df.columns[pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()]].reset_index().reset_index(drop = True)\n",
    "            y = curr_df.cue_destination.reset_index(drop = True)\n",
    "            groups = curr_df['round'].reset_index(drop = True)\n",
    "            \n",
    "            logo = LeaveOneGroupOut()\n",
    "            results = cross_val_score(LogisticRegression(solver='lbfgs', max_iter=1000, random_state = 315), X, y, cv = logo, groups = groups, scoring = 'accuracy')\n",
    "            print(results)\n",
    "            predictions.append(results)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnum = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_file_dir = opj(behav_dir, 'sub{}'.format(subnum))\n",
    "behav_files = glob(opj(behav_file_dir, 'sub*_scan*_timing_*'))\n",
    "\n",
    "org_behav_df = pd.concat((pd.read_csv(f) for f in behav_files), ignore_index=True)\n",
    "behav_df_tmp = cleaning(org_behav_df)\n",
    "behav_df = cleaning2(behav_df_tmp)\n",
    "\n",
    "fmri_file_dir = opj(fMRI_dir, 'sub-MONSTERA{}'.format(subnum))\n",
    "for roi_file_name, roi in rois_dict.items():\n",
    "    print(roi_file_name)\n",
    "    fmri_files = glob(opj(fmri_file_dir, '{}*'.format(roi_file_name)))\n",
    "    fmri_files.sort()\n",
    "\n",
    "    fmri_df = pd.concat((pd.read_csv(f) for f in fmri_files), ignore_index=True)\n",
    "    fmri_df = cleaning3(fmri_df)\n",
    "\n",
    "    # calculating no rolling data\n",
    "    df = behav_df.merge(fmri_df, on=['sub', 'round', 'TR'], how='left')\n",
    "\n",
    "    same_df = df.loc[df.segment == 'same'].drop(columns = ['TR','within_trial_TR'])\n",
    "    same_df = same_df.groupby(['sub','round','trial','pair','destination','valid']).mean().reset_index()\n",
    "\n",
    "    for pair in same_df.pair.unique():\n",
    "        curr_df = same_df.loc[same_df.pair == pair]\n",
    "        curr_destination = curr_df.destination.unique()[0]\n",
    "        curr_df['cue_destination'] = np.where(curr_df.valid, curr_df.destination == curr_destination, curr_df.destination != curr_destination).astype(int)\n",
    "\n",
    "        X = curr_df[curr_df.columns[pd.to_numeric(curr_df.columns, errors='coerce').to_series().notnull()]].reset_index().reset_index(drop = True)\n",
    "        y = curr_df.cue_destination.reset_index(drop = True)\n",
    "        groups = curr_df['round'].reset_index(drop = True)\n",
    "\n",
    "        logo = LeaveOneGroupOut()\n",
    "        results = cross_val_score(LogisticRegression(solver='lbfgs', max_iter=1000, random_state = 315), X, y, cv = logo, groups = groups, scoring = 'accuracy')\n",
    "        print(results)\n",
    "        predictions.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4928467000835422"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.hstack(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
